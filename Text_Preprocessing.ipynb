{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMde96jG3KSLuDEZ9chplAG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxnLQUJN4OGt",
        "outputId": "92bf0b38-b823-4a27-8713-cae0003e7db5"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUOlya-cKJWN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOLvFLJx44x3"
      },
      "source": [
        "# Convert to lowercase\n",
        "def to_lowercase(text):\n",
        "  return text.lower()\n",
        "\n",
        "# Remove numbers\n",
        "def remove_numbers(text):\n",
        "    result = re.sub(r'\\d+', '', text)\n",
        "    return result\n",
        "\n",
        "# Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# Remove whitespace from text\n",
        "def remove_whitespace(text):\n",
        "    return  \" \".join(text.split())\n",
        "\n",
        "# Remove stopwords \n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_text = [word for word in text if word not in stop_words]\n",
        "    return filtered_text\n",
        "\n",
        "# stem words in the list of tokenised words\n",
        "def stem_words(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    stems = [stemmer.stem(word) for word in text]\n",
        "    return stems\n",
        "\n",
        "def combine_data(text):\n",
        "  fc = \" \".join(text)\n",
        "  return fc\n",
        "\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIdeJfSR83Gx"
      },
      "source": [
        "file1 = open(\"Text1.txt\", encoding=\"unicode_escape\")\n",
        "data1 = file1.read()\n",
        "file2 = open(\"Text2.txt\", encoding=\"unicode_escape\")\n",
        "data2 = file2.read()\n",
        "file3 = open(\"Text3.txt\", encoding=\"unicode_escape\")\n",
        "data3 = file3.read()\n",
        "file4 = open(\"LargeText.txt\", encoding=\"unicode_escape\")\n",
        "data4 = file4.read()\n",
        "\n",
        "file1.close()\n",
        "file2.close()\n",
        "file3.close()\n",
        "file4.close()\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIfy1QxMA1O1"
      },
      "source": [
        "# Removing WhiteSpace\n",
        "file1RemoveWhitespace = remove_whitespace(data1)\n",
        "file2RemoveWhitespace = remove_whitespace(data2)\n",
        "file3RemoveWhitespace = remove_whitespace(data3)\n",
        "file4RemoveWhitespace = remove_whitespace(data4)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvc0lLlJCVmX"
      },
      "source": [
        "# Removing Numbers\n",
        "file1RemoveNumbers = remove_numbers(file1RemoveWhitespace)\n",
        "file2RemoveNumbers = remove_numbers(file2RemoveWhitespace)\n",
        "file3RemoveNumbers = remove_numbers(file3RemoveWhitespace)\n",
        "file4RemoveNumbers = remove_numbers(file4RemoveWhitespace)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk-q8x4tClOL"
      },
      "source": [
        "# Removing Punctuation\n",
        "\n",
        "file1RemovePunctuation = remove_punctuation(file1RemoveNumbers)\n",
        "file2RemovePunctuation = remove_punctuation(file2RemoveNumbers)\n",
        "file3RemovePunctuation = remove_punctuation(file3RemoveNumbers)\n",
        "file4RemovePunctuation = remove_punctuation(file4RemoveNumbers)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmB_6ZpBC46O"
      },
      "source": [
        "# Converting to lowercase\n",
        "\n",
        "file1LowerCase = to_lowercase(file1RemovePunctuation)\n",
        "file2LowerCase = to_lowercase(file2RemovePunctuation)\n",
        "file3LowerCase = to_lowercase(file3RemovePunctuation)\n",
        "file4LowerCase = to_lowercase(file4RemovePunctuation)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JZ1JMQADMII"
      },
      "source": [
        "# Stopword Elimination\n",
        "\n",
        "file1StopWordElim = remove_stopwords(file1LowerCase)\n",
        "file2StopWordElim = remove_stopwords(file2LowerCase)\n",
        "file3StopWordElim = remove_stopwords(file3LowerCase)\n",
        "file4StopWordElim = remove_stopwords(file4LowerCase)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtS-6nyYDeBF"
      },
      "source": [
        "# Stemming\n",
        "\n",
        "file1Stemming = stem_words(file1StopWordElim)\n",
        "file2Stemming = stem_words(file2StopWordElim)\n",
        "file3Stemming = stem_words(file3StopWordElim)\n",
        "file4Stemming = stem_words(file4StopWordElim)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv2SDhUzHCqy"
      },
      "source": [
        "# Combine after Lexical Analysis\n",
        "\n",
        "file1Lex = combine_data(file1LowerCase)\n",
        "file2Lex = combine_data(file2LowerCase)\n",
        "file3Lex = combine_data(file3LowerCase)\n",
        "file4Lex = combine_data(file4LowerCase)\n",
        "\n",
        "# Combine after Stopword elimination\n",
        "\n",
        "file1Stop = combine_data(file1StopWordElim)\n",
        "file2Stop = combine_data(file2StopWordElim)\n",
        "file3Stop = combine_data(file3StopWordElim)\n",
        "file4Stop = combine_data(file4StopWordElim)\n",
        "\n",
        "#Combine After Stemming\n",
        "\n",
        "file1Stem = combine_data(file1Stemming)\n",
        "file2Stem = combine_data(file2Stemming)\n",
        "file3Stem = combine_data(file3Stemming)\n",
        "file4Stem = combine_data(file4Stemming)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmPRDuHOEpFq",
        "outputId": "5145d67a-aa23-4c7e-cb7a-10307f0ef91a"
      },
      "source": [
        "print(\"Size of Text1: \")\n",
        "print(\"Before any operations were performed: \",len(data1))\n",
        "print(\"After Lexical Analysis: \",len(file1Lex))\n",
        "print(\"After Stopword elimination: \",len(file1Stop))\n",
        "print(\"After Stemming: \",len(file1Stem))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Text1: \n",
            "Before any operations were performed:  28672\n",
            "After Lexical Analysis:  37953\n",
            "After Stopword elimination:  23443\n",
            "After Stemming:  23443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJF7FYTGc3o",
        "outputId": "a4ace947-281a-441a-ea48-2fa62af16b84"
      },
      "source": [
        "print(\"Size of Text2: \")\n",
        "print(\"Before any operations were performed: \",len(data2))\n",
        "print(\"After Lexical Analysis: \",len(file2Lex))\n",
        "print(\"After Stopword elimination: \",len(file2Stop))\n",
        "print(\"After Stemming: \",len(file2Stem))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Text2: \n",
            "Before any operations were performed:  11373\n",
            "After Lexical Analysis:  21985\n",
            "After Stopword elimination:  13349\n",
            "After Stemming:  13349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiT6_k7SI5zJ",
        "outputId": "ff175381-88f2-43ee-9816-577e7b230b49"
      },
      "source": [
        "print(\"Size of Text3: \")\n",
        "print(\"Before any operations were performed: \",len(data3))\n",
        "print(\"After Lexical Analysis: \",len(file3Lex))\n",
        "print(\"After Stopword elimination: \",len(file3Stop))\n",
        "print(\"After Stemming: \",len(file3Stem))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Text3: \n",
            "Before any operations were performed:  26681\n",
            "After Lexical Analysis:  51731\n",
            "After Stopword elimination:  31643\n",
            "After Stemming:  31643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qupxmc8QI_yA",
        "outputId": "c73dbd97-9dd3-4efb-cd72-2369a82778f5"
      },
      "source": [
        "print(\"Size of LargeText: \")\n",
        "print(\"Before any operations were performed: \",len(data4))\n",
        "print(\"After Lexical Analysis: \",len(file4Lex))\n",
        "print(\"After Stopword elimination: \",len(file4Stop))\n",
        "print(\"After Stemming: \",len(file4Stem))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of LargeText: \n",
            "Before any operations were performed:  661664\n",
            "After Lexical Analysis:  1248039\n",
            "After Stopword elimination:  765963\n",
            "After Stemming:  765963\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}